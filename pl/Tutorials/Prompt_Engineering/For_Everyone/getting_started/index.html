<!doctype html><html lang=pl class=no-js> <head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=author content="Karol Jezierski"><link href=https://kajzer.github.io/future-fluent/pl/Tutorials/Prompt_Engineering/For_Everyone/getting_started/ rel=canonical><link href=../ rel=prev><link href=../../../../Docs/LLM/Inference_and_Serving/ rel=next><link rel=icon href=../../../../../assets/images/favicon.png><meta name=generator content="mkdocs-1.6.1, mkdocs-material-9.5.44"><title>Konfiguracja pierwszego modelu LLM - Future Fluent</title><link rel=stylesheet href=../../../../../assets/stylesheets/main.0253249f.min.css><link rel=stylesheet href=../../../../../assets/stylesheets/palette.06af60db.min.css><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRed+Hat+Mono:400,400i,700,700i&display=fallback"><style>:root{--md-text-font:"Roboto";--md-code-font:"Red Hat Mono"}</style><script>__md_scope=new URL("../../../../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script><link href=../../../../../assets/stylesheets/glightbox.min.css rel=stylesheet><style>
    html.glightbox-open { overflow: initial; height: 100%; }
    .gslide-title { margin-top: 0px; user-select: text; }
    .gslide-desc { color: #666; user-select: text; }
    .gslide-image img { background: white; }
    .gscrollbar-fixer { padding-right: 15px; }
    .gdesc-inner { font-size: 0.75rem; }
    body[data-md-color-scheme="slate"] .gdesc-inner { background: var(--md-default-bg-color);}
    body[data-md-color-scheme="slate"] .gslide-title { color: var(--md-default-fg-color);}
    body[data-md-color-scheme="slate"] .gslide-desc { color: var(--md-default-fg-color);}</style><script src=../../../../../assets/javascripts/glightbox.min.js></script></head> <body dir=ltr data-md-color-scheme=default data-md-color-primary=indigo data-md-color-accent=indigo> <input class=md-toggle data-md-toggle=drawer type=checkbox id=__drawer autocomplete=off> <input class=md-toggle data-md-toggle=search type=checkbox id=__search autocomplete=off> <label class=md-overlay for=__drawer></label> <div data-md-component=skip> <a href=#konfiguracja-pierwszego-modelu-llm class=md-skip> Przejdź do treści </a> </div> <div data-md-component=announce> </div> <header class=md-header data-md-component=header> <nav class="md-header__inner md-grid" aria-label=Nagłówek> <a href=../../../../ title="Future Fluent" class="md-header__button md-logo" aria-label="Future Fluent" data-md-component=logo> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 640 512"><!-- Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M320 0c17.7 0 32 14.3 32 32v64h120c39.8 0 72 32.2 72 72v272c0 39.8-32.2 72-72 72H168c-39.8 0-72-32.2-72-72V168c0-39.8 32.2-72 72-72h120V32c0-17.7 14.3-32 32-32M208 384c-8.8 0-16 7.2-16 16s7.2 16 16 16h32c8.8 0 16-7.2 16-16s-7.2-16-16-16zm96 0c-8.8 0-16 7.2-16 16s7.2 16 16 16h32c8.8 0 16-7.2 16-16s-7.2-16-16-16zm96 0c-8.8 0-16 7.2-16 16s7.2 16 16 16h32c8.8 0 16-7.2 16-16s-7.2-16-16-16zM264 256a40 40 0 1 0-80 0 40 40 0 1 0 80 0m152 40a40 40 0 1 0 0-80 40 40 0 1 0 0 80M48 224h16v192H48c-26.5 0-48-21.5-48-48v-96c0-26.5 21.5-48 48-48m544 0c26.5 0 48 21.5 48 48v96c0 26.5-21.5 48-48 48h-16V224z"/></svg> </a> <label class="md-header__button md-icon" for=__drawer> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg> </label> <div class=md-header__title data-md-component=header-title> <div class=md-header__ellipsis> <div class=md-header__topic> <span class=md-ellipsis> Future Fluent </span> </div> <div class=md-header__topic data-md-component=header-topic> <span class=md-ellipsis> Konfiguracja pierwszego modelu LLM </span> </div> </div> </div> <form class=md-header__option data-md-component=palette> <input class=md-option data-md-color-media=(prefers-color-scheme) data-md-color-scheme=default data-md-color-primary=indigo data-md-color-accent=indigo aria-label="Switch to dark mode" type=radio name=__palette id=__palette_0> <label class="md-header__button md-icon" title="Switch to dark mode" for=__palette_1 hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7a5 5 0 0 0-5 5 5 5 0 0 0 5 5h4v-1.9H7c-1.71 0-3.1-1.39-3.1-3.1M8 13h8v-2H8zm9-6h-4v1.9h4c1.71 0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4a5 5 0 0 0 5-5 5 5 0 0 0-5-5"/></svg> </label> <input class=md-option data-md-color-media="(prefers-color-scheme: dark)" data-md-color-scheme=slate data-md-color-primary=deep-purple data-md-color-accent=purple aria-label="Switch to light mode" type=radio name=__palette id=__palette_1> <label class="md-header__button md-icon" title="Switch to light mode" for=__palette_2 hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M12 7a5 5 0 0 1 5 5 5 5 0 0 1-5 5 5 5 0 0 1-5-5 5 5 0 0 1 5-5m0 2a3 3 0 0 0-3 3 3 3 0 0 0 3 3 3 3 0 0 0 3-3 3 3 0 0 0-3-3m0-7 2.39 3.42C13.65 5.15 12.84 5 12 5s-1.65.15-2.39.42zM3.34 7l4.16-.35A7.2 7.2 0 0 0 5.94 8.5c-.44.74-.69 1.5-.83 2.29zm.02 10 1.76-3.77a7.131 7.131 0 0 0 2.38 4.14zM20.65 7l-1.77 3.79a7.02 7.02 0 0 0-2.38-4.15zm-.01 10-4.14.36c.59-.51 1.12-1.14 1.54-1.86.42-.73.69-1.5.83-2.29zM12 22l-2.41-3.44c.74.27 1.55.44 2.41.44.82 0 1.63-.17 2.37-.44z"/></svg> </label> <input class=md-option data-md-color-media="(prefers-color-scheme: light)" data-md-color-scheme=default data-md-color-primary=teal data-md-color-accent=green aria-label="Switch to system preference" type=radio name=__palette id=__palette_2> <label class="md-header__button md-icon" title="Switch to system preference" for=__palette_0 hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="m17.75 4.09-2.53 1.94.91 3.06-2.63-1.81-2.63 1.81.91-3.06-2.53-1.94L12.44 4l1.06-3 1.06 3zm3.5 6.91-1.64 1.25.59 1.98-1.7-1.17-1.7 1.17.59-1.98L15.75 11l2.06-.05L18.5 9l.69 1.95zm-2.28 4.95c.83-.08 1.72 1.1 1.19 1.85-.32.45-.66.87-1.08 1.27C15.17 23 8.84 23 4.94 19.07c-3.91-3.9-3.91-10.24 0-14.14.4-.4.82-.76 1.27-1.08.75-.53 1.93.36 1.85 1.19-.27 2.86.69 5.83 2.89 8.02a9.96 9.96 0 0 0 8.02 2.89m-1.64 2.02a12.08 12.08 0 0 1-7.8-3.47c-2.17-2.19-3.33-5-3.49-7.82-2.81 3.14-2.7 7.96.31 10.98 3.02 3.01 7.84 3.12 10.98.31"/></svg> </label> </form> <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script> <div class=md-header__option> <div class=md-select> <button class="md-header__button md-icon" aria-label="Wybierz język"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="m12.87 15.07-2.54-2.51.03-.03A17.5 17.5 0 0 0 14.07 6H17V4h-7V2H8v2H1v2h11.17C11.5 7.92 10.44 9.75 9 11.35 8.07 10.32 7.3 9.19 6.69 8h-2c.73 1.63 1.73 3.17 2.98 4.56l-5.09 5.02L4 19l5-5 3.11 3.11zM18.5 10h-2L12 22h2l1.12-3h4.75L21 22h2zm-2.62 7 1.62-4.33L19.12 17z"/></svg> </button> <div class=md-select__inner> <ul class=md-select__list> <li class=md-select__item> <a href=../../../../../Tutorials/Prompt_Engineering/For_Everyone/getting_started/ hreflang=en class=md-select__link> English </a> </li> <li class=md-select__item> <a href=./ hreflang=pl class=md-select__link> Polski </a> </li> </ul> </div> </div> </div> <label class="md-header__button md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg> </label> <div class=md-search data-md-component=search role=dialog> <label class=md-search__overlay for=__search></label> <div class=md-search__inner role=search> <form class=md-search__form name=search> <input type=text class=md-search__input name=query aria-label=Szukaj placeholder=Szukaj autocapitalize=off autocorrect=off autocomplete=off spellcheck=false data-md-component=search-query required> <label class="md-search__icon md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg> </label> <nav class=md-search__options aria-label=Szukaj> <button type=reset class="md-search__icon md-icon" title=Wyczyść aria-label=Wyczyść tabindex=-1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg> </button> </nav> <div class=md-search__suggest data-md-component=search-suggest></div> </form> <div class=md-search__output> <div class=md-search__scrollwrap tabindex=0 data-md-scrollfix> <div class=md-search-result data-md-component=search-result> <div class=md-search-result__meta> Inicjowanie wyszukiwania </div> <ol class=md-search-result__list role=presentation></ol> </div> </div> </div> </div> </div> <div class=md-header__source> <a href=https://github.com/kajzer/future-fluent title="Przejdź do repozytorium" class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81"/></svg> </div> <div class=md-source__repository> kajzer.github.io/future-fluent/ </div> </a> </div> </nav> </header> <div class=md-container data-md-component=container> <nav class=md-tabs aria-label=Zakładki data-md-component=tabs> <div class=md-grid> <ul class=md-tabs__list> <li class=md-tabs__item> <a href=../../../../ class=md-tabs__link> Strona Główna </a> </li> <li class="md-tabs__item md-tabs__item--active"> <a href=../../ class=md-tabs__link> Tutoriale </a> </li> <li class=md-tabs__item> <a href=../../../../Docs/LLM/Inference_and_Serving/ class=md-tabs__link> Materiały </a> </li> </ul> </div> </nav> <main class=md-main data-md-component=main> <div class="md-main__inner md-grid"> <div class="md-sidebar md-sidebar--primary" data-md-component=sidebar data-md-type=navigation> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--primary md-nav--lifted" aria-label=Nawigacja data-md-level=0> <label class=md-nav__title for=__drawer> <a href=../../../../ title="Future Fluent" class="md-nav__button md-logo" aria-label="Future Fluent" data-md-component=logo> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 640 512"><!-- Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M320 0c17.7 0 32 14.3 32 32v64h120c39.8 0 72 32.2 72 72v272c0 39.8-32.2 72-72 72H168c-39.8 0-72-32.2-72-72V168c0-39.8 32.2-72 72-72h120V32c0-17.7 14.3-32 32-32M208 384c-8.8 0-16 7.2-16 16s7.2 16 16 16h32c8.8 0 16-7.2 16-16s-7.2-16-16-16zm96 0c-8.8 0-16 7.2-16 16s7.2 16 16 16h32c8.8 0 16-7.2 16-16s-7.2-16-16-16zm96 0c-8.8 0-16 7.2-16 16s7.2 16 16 16h32c8.8 0 16-7.2 16-16s-7.2-16-16-16zM264 256a40 40 0 1 0-80 0 40 40 0 1 0 80 0m152 40a40 40 0 1 0 0-80 40 40 0 1 0 0 80M48 224h16v192H48c-26.5 0-48-21.5-48-48v-96c0-26.5 21.5-48 48-48m544 0c26.5 0 48 21.5 48 48v96c0 26.5-21.5 48-48 48h-16V224z"/></svg> </a> Future Fluent </label> <div class=md-nav__source> <a href=https://github.com/kajzer/future-fluent title="Przejdź do repozytorium" class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81"/></svg> </div> <div class=md-source__repository> kajzer.github.io/future-fluent/ </div> </a> </div> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../../ class=md-nav__link> <span class=md-ellipsis> Strona Główna </span> </a> </li> <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2 checked> <label class=md-nav__link for=__nav_2 id=__nav_2_label tabindex> <span class=md-ellipsis> Tutoriale </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_2_label aria-expanded=true> <label class=md-nav__title for=__nav_2> <span class="md-nav__icon md-icon"></span> Tutoriale </label> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--active md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2_1 checked> <div class="md-nav__link md-nav__container"> <a href=../../ class="md-nav__link "> <span class=md-ellipsis> Prompt Engineering </span> </a> <label class="md-nav__link " for=__nav_2_1 id=__nav_2_1_label tabindex=0> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_2_1_label aria-expanded=true> <label class=md-nav__title for=__nav_2_1> <span class="md-nav__icon md-icon"></span> Prompt Engineering </label> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--active md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2_1_2 checked> <div class="md-nav__link md-nav__container"> <a href=../ class="md-nav__link "> <span class=md-ellipsis> Dla Każdego </span> </a> <label class="md-nav__link " for=__nav_2_1_2 id=__nav_2_1_2_label tabindex=0> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav data-md-level=3 aria-labelledby=__nav_2_1_2_label aria-expanded=true> <label class=md-nav__title for=__nav_2_1_2> <span class="md-nav__icon md-icon"></span> Dla Każdego </label> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--active"> <input class="md-nav__toggle md-toggle" type=checkbox id=__toc> <label class="md-nav__link md-nav__link--active" for=__toc> <span class=md-ellipsis> Konfiguracja pierwszego modelu LLM </span> <span class="md-nav__icon md-icon"></span> </label> <a href=./ class="md-nav__link md-nav__link--active"> <span class=md-ellipsis> Konfiguracja pierwszego modelu LLM </span> </a> <nav class="md-nav md-nav--secondary" aria-label="Spis treści"> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> Spis treści </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a href=#loaklne-vs-hostowane-modele class=md-nav__link> <span class=md-ellipsis> Loaklne vs. Hostowane Modele </span> </a> <nav class=md-nav aria-label="Loaklne vs. Hostowane Modele"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#lokalne-modele class=md-nav__link> <span class=md-ellipsis> Lokalne Modele </span> </a> </li> <li class=md-nav__item> <a href=#hostowane-modele class=md-nav__link> <span class=md-ellipsis> Hostowane Modele </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#opcje-interfejsow-do-pracy-z-llm-ami class=md-nav__link> <span class=md-ellipsis> Opcje interfejsów do pracy z LLM-ami </span> </a> </li> <li class=md-nav__item> <a href=#podsumowanie-od-czego-zaczac class=md-nav__link> <span class=md-ellipsis> Podsumowanie: Od czego zacząć? </span> </a> </li> <li class=md-nav__item> <a href=#rekomendacje class=md-nav__link> <span class=md-ellipsis> Rekomendacje </span> </a> <nav class=md-nav aria-label=Rekomendacje> <ul class=md-nav__list> <li class=md-nav__item> <a href=#hostowany-interfejs-z-darmowym-dostepem class=md-nav__link> <span class=md-ellipsis> Hostowany interfejs z darmowym dostępem </span> </a> </li> <li class=md-nav__item> <a href=#lokalny-llm-z-interfejsem-graficznym class=md-nav__link> <span class=md-ellipsis> Lokalny LLM z interfejsem graficznym </span> </a> </li> <li class=md-nav__item> <a href=#interfejs-przez-openrouter-darmowe-i-patne-llm-y class=md-nav__link> <span class=md-ellipsis> Interfejs przez OpenRouter — darmowe i płatne LLM-y </span> </a> </li> <li class=md-nav__item> <a href=#lokalne-modele-dla-zaawansowanych-uzytkownikow class=md-nav__link> <span class=md-ellipsis> Lokalne modele dla zaawansowanych użytkowników </span> </a> </li> <li class=md-nav__item> <a href=#wiecej-opcji class=md-nav__link> <span class=md-ellipsis> Więcej Opcji </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#co-dalej class=md-nav__link> <span class=md-ellipsis> Co dalej? </span> </a> </li> <li class=md-nav__item> <a href=#bonus class=md-nav__link> <span class=md-ellipsis> Bonus </span> </a> </li> </ul> </nav> </li> </ul> </nav> </li> </ul> </nav> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_3> <label class=md-nav__link for=__nav_3 id=__nav_3_label tabindex=0> <span class=md-ellipsis> Materiały </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_3_label aria-expanded=false> <label class=md-nav__title for=__nav_3> <span class="md-nav__icon md-icon"></span> Materiały </label> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_3_1> <label class=md-nav__link for=__nav_3_1 id=__nav_3_1_label tabindex=0> <span class=md-ellipsis> LLM </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_3_1_label aria-expanded=false> <label class=md-nav__title for=__nav_3_1> <span class="md-nav__icon md-icon"></span> LLM </label> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_3_1_1> <div class="md-nav__link md-nav__container"> <a href=../../../../Docs/LLM/Inference_and_Serving/ class="md-nav__link "> <span class=md-ellipsis> Inference and Serving </span> </a> </div> <nav class=md-nav data-md-level=3 aria-labelledby=__nav_3_1_1_label aria-expanded=false> <label class=md-nav__title for=__nav_3_1_1> <span class="md-nav__icon md-icon"></span> Inference and Serving </label> <ul class=md-nav__list data-md-scrollfix> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_3_1_2> <div class="md-nav__link md-nav__container"> <a href=../../../../Docs/LLM/Resources/ class="md-nav__link "> <span class=md-ellipsis> Materiały </span> </a> </div> <nav class=md-nav data-md-level=3 aria-labelledby=__nav_3_1_2_label aria-expanded=false> <label class=md-nav__title for=__nav_3_1_2> <span class="md-nav__icon md-icon"></span> Materiały </label> <ul class=md-nav__list data-md-scrollfix> </ul> </nav> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_3_2> <label class=md-nav__link for=__nav_3_2 id=__nav_3_2_label tabindex=0> <span class=md-ellipsis> Prompt Engineering </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_3_2_label aria-expanded=false> <label class=md-nav__title for=__nav_3_2> <span class="md-nav__icon md-icon"></span> Prompt Engineering </label> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_3_2_1> <div class="md-nav__link md-nav__container"> <a href=../../../../Docs/Prompt_Engineering/Papers/ class="md-nav__link "> <span class=md-ellipsis> Papery </span> </a> </div> <nav class=md-nav data-md-level=3 aria-labelledby=__nav_3_2_1_label aria-expanded=false> <label class=md-nav__title for=__nav_3_2_1> <span class="md-nav__icon md-icon"></span> Papery </label> <ul class=md-nav__list data-md-scrollfix> </ul> </nav> </li> </ul> </nav> </li> </ul> </nav> </li> </ul> </nav> </div> </div> </div> <div class="md-sidebar md-sidebar--secondary" data-md-component=sidebar data-md-type=toc> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--secondary" aria-label="Spis treści"> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> Spis treści </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a href=#loaklne-vs-hostowane-modele class=md-nav__link> <span class=md-ellipsis> Loaklne vs. Hostowane Modele </span> </a> <nav class=md-nav aria-label="Loaklne vs. Hostowane Modele"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#lokalne-modele class=md-nav__link> <span class=md-ellipsis> Lokalne Modele </span> </a> </li> <li class=md-nav__item> <a href=#hostowane-modele class=md-nav__link> <span class=md-ellipsis> Hostowane Modele </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#opcje-interfejsow-do-pracy-z-llm-ami class=md-nav__link> <span class=md-ellipsis> Opcje interfejsów do pracy z LLM-ami </span> </a> </li> <li class=md-nav__item> <a href=#podsumowanie-od-czego-zaczac class=md-nav__link> <span class=md-ellipsis> Podsumowanie: Od czego zacząć? </span> </a> </li> <li class=md-nav__item> <a href=#rekomendacje class=md-nav__link> <span class=md-ellipsis> Rekomendacje </span> </a> <nav class=md-nav aria-label=Rekomendacje> <ul class=md-nav__list> <li class=md-nav__item> <a href=#hostowany-interfejs-z-darmowym-dostepem class=md-nav__link> <span class=md-ellipsis> Hostowany interfejs z darmowym dostępem </span> </a> </li> <li class=md-nav__item> <a href=#lokalny-llm-z-interfejsem-graficznym class=md-nav__link> <span class=md-ellipsis> Lokalny LLM z interfejsem graficznym </span> </a> </li> <li class=md-nav__item> <a href=#interfejs-przez-openrouter-darmowe-i-patne-llm-y class=md-nav__link> <span class=md-ellipsis> Interfejs przez OpenRouter — darmowe i płatne LLM-y </span> </a> </li> <li class=md-nav__item> <a href=#lokalne-modele-dla-zaawansowanych-uzytkownikow class=md-nav__link> <span class=md-ellipsis> Lokalne modele dla zaawansowanych użytkowników </span> </a> </li> <li class=md-nav__item> <a href=#wiecej-opcji class=md-nav__link> <span class=md-ellipsis> Więcej Opcji </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#co-dalej class=md-nav__link> <span class=md-ellipsis> Co dalej? </span> </a> </li> <li class=md-nav__item> <a href=#bonus class=md-nav__link> <span class=md-ellipsis> Bonus </span> </a> </li> </ul> </nav> </div> </div> </div> <div class=md-content data-md-component=content> <article class="md-content__inner md-typeset"> <a href=https://github.com/kajzer/future-fluent/edit/master/docs/pl/Tutorials/Prompt_Engineering/For_Everyone/getting_started.md title="Edytuj tę stronę" class="md-content__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M10 20H6V4h7v5h5v3.1l2-2V8l-6-6H6c-1.1 0-2 .9-2 2v16c0 1.1.9 2 2 2h4zm10.2-7c.1 0 .3.1.4.2l1.3 1.3c.2.2.2.6 0 .8l-1 1-2.1-2.1 1-1c.1-.1.2-.2.4-.2m0 3.9L14.1 23H12v-2.1l6.1-6.1z"/></svg> </a> <a href=https://github.com/kajzer/future-fluent/raw/master/docs/pl/Tutorials/Prompt_Engineering/For_Everyone/getting_started.md title="Zobacz kod źródłowy tej strony" class="md-content__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M17 18c.56 0 1 .44 1 1s-.44 1-1 1-1-.44-1-1 .44-1 1-1m0-3c-2.73 0-5.06 1.66-6 4 .94 2.34 3.27 4 6 4s5.06-1.66 6-4c-.94-2.34-3.27-4-6-4m0 6.5a2.5 2.5 0 0 1-2.5-2.5 2.5 2.5 0 0 1 2.5-2.5 2.5 2.5 0 0 1 2.5 2.5 2.5 2.5 0 0 1-2.5 2.5M9.27 20H6V4h7v5h5v4.07c.7.08 1.36.25 2 .49V8l-6-6H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h4.5a8.2 8.2 0 0 1-1.23-2"/></svg> </a> <h1 id=konfiguracja-pierwszego-modelu-llm>Konfiguracja pierwszego modelu LLM<a class=headerlink href=#konfiguracja-pierwszego-modelu-llm title="Permanent link">&para;</a></h1> <p>Najlepszym sposobem na naukę prompt engineeringu jest po prostu działanie i eksperymentowanie. Ten przewodnik skupia się na praktycznych metodach pracy z dużymi modelami językowymi (LLM), niezależnie od tego, czy uruchamiasz je lokalnie na własnym sprzęcie, czy korzystasz z rozwiązań chmurowych. Poniżej znajdziesz przegląd narzędzi, platform i interfejsów, które pozwolą Ci od razu zacząć przygodę z LLM-ami.</p> <div class="admonition question"> <p class=admonition-title>Nie martw się</p> <p>Spokojnie, jeśli jakieś pojęcia czy zwroty brzmią obco, nie ma się czym martwić. Wszystko wytłumaczymy w następnych rozdziałach.</p> </div> <h2 id=loaklne-vs-hostowane-modele>Loaklne vs. Hostowane Modele<a class=headerlink href=#loaklne-vs-hostowane-modele title="Permanent link">&para;</a></h2> <h3 id=lokalne-modele>Lokalne Modele<a class=headerlink href=#lokalne-modele title="Permanent link">&para;</a></h3> <p>Modele lokalne działają całkowicie na Twoim sprzęcie, dając Ci pełną kontrolę nad prywatnością danych i możliwością dostosowania wszystkiego pod siebie. Narzędzia takie jak <a href=https://ollama.com/ target=_blank>Ollama</a> czy <a href=https://lmstudio.ai/ target=_blank>LM Studio</a> upraszczają cały proces, dzięki nim nie musisz martwić się o większość ustawień, żeby uruchomić model (np. Mistral-7B lub Llama3-8B). Wystarczy kilka kliknięć albo jedna linijka w terminalu (np. <code>ollama run llama2</code>), żeby pobrać i uruchomić LLM.</p> <p>Taki sposób uruchamiania modeli świetnie sprawdza się przy wrażliwych projektach, bo dane nigdy nie opuszczają Twojego urządzenia. Trzeba jednak pamiętać o ograniczeniach sprzętowych — np. do działania modelu 7B potrzebujesz co najmniej 8 GB RAM, a przy większych modelach (np. 70B) przyda się mocna karta graficzna lub specjalna wersja modelu z tzw. kwantyzacją.</p> <h3 id=hostowane-modele>Hostowane Modele<a class=headerlink href=#hostowane-modele title="Permanent link">&para;</a></h3> <p>Modele hostowane, oferowane przez firmy takie jak OpenAI, Anthropic czy Google, zdejmują z użytkownika cały ciężar zarządzania infrastrukturą. Dzięki nim możesz korzystać z najnowszych modeli (np. GPT-4 czy Claude 3.7) za pomocą API albo interfejsów graficznych. To rozwiązanie bardzo wygodne i łatwo skalowalne bo nie musisz się martwić o sprzęt czy aktualizacje, bo tym wszystkim zajmuje się dostawca.</p> <p>Z drugiej strony, poleganie na zewnętrznych usługach wiąże się z ryzykiem, Twoje zapytania i odpowiedzi mogą być zapisywane lub wykorzystywane do dalszego trenowania modeli. Do tego, przy intensywnym używaniu API lub subskrypcjach premium, koszty mogą szybko rosnąć.</p> <h2 id=opcje-interfejsow-do-pracy-z-llm-ami>Opcje interfejsów do pracy z LLM-ami<a class=headerlink href=#opcje-interfejsow-do-pracy-z-llm-ami title="Permanent link">&para;</a></h2> <p>Interfejsy przyjazne dla początkujących, takie jak LM Studio i Jan, oferują intuicyjne środowiska graficzne do pracy z lokalnymi modelami. Te narzędzia wspierają funkcje takie jak:</p> <ul> <li>Przeglądanie modeli i pobieranie ich z repozytoriów, np. Hugging Face.</li> <li>Interfejsy czatowe z zapisaną historią rozmów.</li> <li>Dostosowywanie parametrów (np. temperatura, top-p sampling) generowania.</li> </ul> <p>Do współpracy lub dla wielu użytkowników, Open WebUI oferuje samodzielnie hostowany interfejs webowy z funkcjami uwierzytelniania użytkowników oraz "document retrical" (RAG). Z kolei SillyTavern i AnythingLLM są skierowane do bardziej zaawansowanych użytkowników, oferując systemy pluginów do generowania obrazów, przeszukiwania internetu i integracji z API.</p> <div class="admonition danger"> <p class=admonition-title>Uwaga</p> <p>Pojawiały się pewne wątpliwości niektórych lokalnie uruchamianych interfejsach. Na przykład LM Studio, choć po pobraniu modelu nie łączy się z Internetem i wyraźnie deklaruje na stronie głównej: "The app does not collect data or monitor your actions. Your data stays local on your machine", to jednak pojawiły się pytania dotyczące jego warunków użytkowania. Warto więc dokładnie zapoznać się z regulaminem przed rozpoczęciem pracy z jakimkolwiek narzędziem.</p> </div> <h2 id=podsumowanie-od-czego-zaczac>Podsumowanie: Od czego zacząć?<a class=headerlink href=#podsumowanie-od-czego-zaczac title="Permanent link">&para;</a></h2> <p>Dla początkujących, modele hostowane to najprostszy sposób na start, nie trzeba nic instalować ani konfigurować. Platformy takie jak OpenAI często oferują darmowe plany, które świetnie nadają się do nauki i testów. Gdy już poczujesz się pewniej, warto rozważyć przejście na modele lokalne przez Ollama lub LM Studio, które dają więcej swobody, prywatności i oszczędności przy bardziej wyspecjalizowanych zastosowaniach.</p> <div class="admonition warning"> <p class=admonition-title>Wybór UI</p> <p>Jeśli chcesz uczyć się razem z nami, np. jak dostosowywać parametry LLM-ów, warto wybrać środowisko, które na to pozwala. Niektóre darmowe wersje modeli hostowanych mogą ograniczać albo ukrywać dostęp do takich opcji. Podamy kilka narzędzi, ale pamiętaj, że jest to stan na moment pisania tego przewodnika, więc przed wyborem najlepiej samodzielnie sprawdzić, co dokładnie oferują.</p> </div> <h2 id=rekomendacje>Rekomendacje<a class=headerlink href=#rekomendacje title="Permanent link">&para;</a></h2> <p>Poniższe opcje są ułożone według rosnącego poziomu trudności. Zaczynamy od najprostszych w konfiguracji, a kończymy na tych bardziej zaawansowanych, wymagających nieco więcej wiedzy technicznej.</p> <h3 id=hostowany-interfejs-z-darmowym-dostepem>Hostowany interfejs z darmowym dostępem<a class=headerlink href=#hostowany-interfejs-z-darmowym-dostepem title="Permanent link">&para;</a></h3> <p>Najprostsza opcja to skorzystanie z hostowanego, darmowego interfejsu użytkownika. Popularne platformy to <a href=https://chatgpt.com/ target=_blank>ChatGPT</a> i <a href=https://claude.ai/ target=_blank>Claude</a>, ale możesz również porozmawiać z <img alt=🦅 class=twemoji src=https://cdn.jsdelivr.net/gh/jdecked/twemoji@15.1.0/assets/svg/1f985.svg title=:eagle:> <a href=https://bielik.ai/ target=_blank>Bielikiem</a> przez UI. Trzeba jednak pamiętać, że w chwili pisania tego przewodnika dostęp do bardziej zaawansowanych funkcji zwykle wymaga płatnej subskrypcji. Jeśli chcesz eksplorować te możliwości bez ponoszenia kosztów, polecamy <a href=https://aistudio.google.com/ target=_blank>Google AI Studio</a>, które w ramach darmowego planu udostępnia sporo zaawansowanych opcji do pracy z modelami.</p> <figure> <a class=glightbox href=../../../../../img/prompt_engineering/for_everyone/aistudio.png data-type=image data-width=auto data-height=auto data-desc-position=bottom><img alt="Image title" src=../../../../../img/prompt_engineering/for_everyone/aistudio.png style=height:65%;width:65%></a> <figcaption>Google AI Studio</figcaption> </figure> <h3 id=lokalny-llm-z-interfejsem-graficznym>Lokalny LLM z interfejsem graficznym<a class=headerlink href=#lokalny-llm-z-interfejsem-graficznym title="Permanent link">&para;</a></h3> <div class="admonition tip"> <p class=admonition-title>Wymagania Sprzętowe</p> <p>Ta opcja wymaga mocniejszego sprzętu, najlepiej komputera z kartą graficzną (GPU). Co prawda można uruchamiać mniejsze modele w wersji "skwantyzowanej" (czyli zoptymalizowanej pod kątem szybkości i niższego zużycia zasobów), ale trzeba liczyć się z tym, że jakość odpowiedzi może być nieco niższa w porównaniu do pełnych wersji modeli.</p> </div> <p>Wejdź na stronę <a href=https://lmstudio.ai/ target=_blank>LM Studio</a> i pobierz wersję odpowiednią dla Twojego systemu operacyjnego. Po zainstalowaniu, uruchom aplikację.</p> <figure> <a class=glightbox href=../../../../../img/prompt_engineering/for_everyone/lmstudio.png data-type=image data-width=auto data-height=auto data-desc-position=bottom><img alt="Image title" src=../../../../../img/prompt_engineering/for_everyone/lmstudio.png style=height:65%;width:65%></a> <figcaption>LM Studio</figcaption> </figure> <p>Aplikacja nie zadziała od razu, najpierw trzeba pobrać model. Aby to zrobić, przejdź do zakładki <span class=twemoji><svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 512 512"><!-- Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M416 208c0 45.9-14.9 88.3-40 122.7l126.6 126.7c12.5 12.5 12.5 32.8 0 45.3s-32.8 12.5-45.3 0L330.7 376c-34.4 25.2-76.8 40-122.7 40C93.1 416 0 322.9 0 208S93.1 0 208 0s208 93.1 208 208M208 352a144 144 0 1 0 0-288 144 144 0 1 0 0 288"/></svg></span> "Discover" (znajdziesz ją po lewej stronie okna aplikacji), a następnie wybierz interesujący Cię model i wersję kwantyzacji, np. <code>Q4_K_M</code>, i kliknij pobierz. Na początek polecamy mniejszy model, taki jak <code>Bielik-11B-v2.5-Instruct</code> lub <code>Mistral-7B-Instruct-v0.3-GGUF</code>, oferuje on równowagę między jakością a wymaganiami sprzętowymi. Idealny do nauki i pierwszych eksperymentów. Jeśli nie masz dostępu do GPU, a mimo to chcesz uruchomić model lokalnie, możesz spróbować mniejszych modeli, takich jak <code>Bielik-4.5B-v3.0-Instruct-GGUF</code>, <code>Bielik-1.5B-v3.0-Instruct-GGUF</code> lub <code>Gemma 4B QAT</code> (Quantization Aware Training). Te modele są zaprojektowane z myślą o większej wydajności i mogą działać nawet na komputerach bez karty graficznej, choć ich szybkość i płynność odpowiedzi będą zależeć od możliwości Twojego sprzętu.</p> <figure> <a class=glightbox href=../../../../../img/prompt_engineering/for_everyone/lmstudio-bielik.png data-type=image data-width=auto data-height=auto data-desc-position=bottom><img alt="Image title" src=../../../../../img/prompt_engineering/for_everyone/lmstudio-bielik.png style=height:65%;width:65%></a> <figcaption>Wyszukaj i pobierz model w LM Studio</figcaption> </figure> <p>Po zakończeniu pobierania przejdź do zakładki <span class=twemoji><svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M12 3C6.5 3 2 6.58 2 11a7.22 7.22 0 0 0 2.75 5.5c0 .6-.42 2.17-2.75 4.5 2.37-.11 4.64-1 6.47-2.5 1.14.33 2.34.5 3.53.5 5.5 0 10-3.58 10-8s-4.5-8-10-8m0 14c-4.42 0-8-2.69-8-6s3.58-6 8-6 8 2.69 8 6-3.58 6-8 6"/></svg></span> "Chat", a następnie w górnej części ekranu czatu wybierz model z rozwijanej listy („Select a model to load”), aby go załadować i rozpocząć rozmowę.</p> <figure> <a class=glightbox href=../../../../../img/prompt_engineering/for_everyone/lmstudio-chat-bielik.png data-type=image data-width=auto data-height=auto data-desc-position=bottom><img alt="Image title" src=../../../../../img/prompt_engineering/for_everyone/lmstudio-chat-bielik.png style=height:65%;width:65%></a> <figcaption>Załadowanie modelu</figcaption> </figure> <p>i możesz z nim rozmawiać.</p> <figure> <a class=glightbox href=../../../../../img/prompt_engineering/for_everyone/lmstudio-chat-interact-bielik.png data-type=image data-width=auto data-height=auto data-desc-position=bottom><img alt="Image title" src=../../../../../img/prompt_engineering/for_everyone/lmstudio-chat-interact-bielik.png style=height:65%;width:65%></a> <figcaption>Interkacja z LLM</figcaption> </figure> <p>Po zakończeniu pracy pamiętaj, aby odmontować (eject) model i zamknąć aplikację. Dzięki temu zwolnisz zasoby systemowe i unikniesz niepotrzebnego obciążenia sprzętu.</p> <h3 id=interfejs-przez-openrouter-darmowe-i-patne-llm-y>Interfejs przez OpenRouter — darmowe i płatne LLM-y<a class=headerlink href=#interfejs-przez-openrouter-darmowe-i-patne-llm-y title="Permanent link">&para;</a></h3> <p>Aby korzystać z <a href=https://jan.ai/ target=_blank>Jan.ai</a> (lub podobnej platformy, np. <a href=https://anythingllm.com/ target=_blank>AnythingLLM</a>) z OpenRouterem, potrzebne są dodatkowe kroki konfiguracyjne:</p> <ul> <li>Pobierz i zainstaluj <a href=https://jan.ai/ target=_blank>Jan.ai</a> z oficjalnej strony.</li> <li>Zarejestruj się na <a href=https://openrouter.ai/ target=_blank>OpenRouter</a>.</li> <li>Po zalogowaniu się na stronie OpenRouter przejdź do Settings → API Keys.</li> <li>Wygeneruj nowy klucz API i od razu go skopiuj, będzie wyglądał mniej więcej tak: <code>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</code>.</li> </ul> <div class="admonition tip"> <p class=admonition-title>API Key</p> <p>Klucz API możesz zobaczyć tylko raz — jeśli zapomnisz go skopiować, po prostu wygeneruj nowy.</p> </div> <ul> <li>W aplikacji Jan.ai przejdź do Settings → Remote Engine → OpenRouter i wklej swój klucz API w odpowiednie pole. Dzięki temu aplikacja będzie mogła korzystać z modeli udostępnianych przez OpenRouter.</li> <li>Teraz możesz rozpocząć nowy wątek i wybrać model, klikając selektor modeli na dole okna czatu. Wybierz Cloud → wpisz „free”, a następnie przewiń, aby znaleźć OpenRouter i wybrać swój model. Pamiętaj, aby zapoznać się z warunkami korzystania z modelu, ponieważ niektóre darmowe modele są dostępne tylko dla użytkowników, którzy dokonali wcześniej jakiegokolwiek zakupu.</li> </ul> <div class="admonition tip"> <p class=admonition-title>Darmowe modele</p> <p>Możesz np. wybrać model: <code>nvidia/llama-3.3-nemotron-super-9b-v1:free</code></p> </div> <p>Opcjonalnie – Korzystanie z modeli Google za darmo: Jeśli wolisz korzystać z modeli Google, możesz uzyskać darmowy klucz API, klikając „Get API Key” na górze interfejsu <a href=https://aistudio.google.com/ target=_blank>Google AI Studio</a>. Następnie postępuj zgodnie z tymi samymi krokami, ale pamiętaj, aby wybrać Google jako dostawcę, a nie OpenRouter.</p> <figure> <a class=glightbox href=../../../../../img/prompt_engineering/for_everyone/jan.png data-type=image data-width=auto data-height=auto data-desc-position=bottom><img alt="Image title" src=../../../../../img/prompt_engineering/for_everyone/jan.png style=height:65%;width:65%></a> <figcaption>Jan</figcaption> </figure> <h3 id=lokalne-modele-dla-zaawansowanych-uzytkownikow>Lokalne modele dla zaawansowanych użytkowników<a class=headerlink href=#lokalne-modele-dla-zaawansowanych-uzytkownikow title="Permanent link">&para;</a></h3> <p>Jeśli chcesz używać LLM bezpośrednio z terminala, korzystając z narzędzi takich jak cURL lub z poziomu języka programowania, na przykład Python, możesz zapoznać się z dodatkowymi metodami w sekcji <a href=../../../../Docs/LLM/Inference_and_Serving/ >Inference and Serving</a>.</p> <h3 id=wiecej-opcji>Więcej Opcji<a class=headerlink href=#wiecej-opcji title="Permanent link">&para;</a></h3> <p>Możesz sprawdzić więcej opcji interfejsów użytkownika, silników inferencyjnych i darmowych API, takich jak OpenRouter, przechodząc do <a href=../../../../Docs/LLM/Resources/ >LLM Resources</a></p> <h2 id=co-dalej>Co dalej?<a class=headerlink href=#co-dalej title="Permanent link">&para;</a></h2> <p>Eksperymentuj z LLM, który właśnie zainstalowałeś, a następnie przejdź do kolejnej sekcji.</p> <h2 id=bonus>Bonus<a class=headerlink href=#bonus title="Permanent link">&para;</a></h2> <p>Jeśli masz ochotę na odrobinę nostalgii i zabawy, możesz zainstalować <a href=https://felixrieseberg.github.io/clippy/#window-video target=_blank>Clippy’ego</a>, załadować <img alt=🦅 class=twemoji src=https://cdn.jsdelivr.net/gh/jdecked/twemoji@15.1.0/assets/svg/1f985.svg title=:eagle:> Bielika (format GGUF np. <code>speakleash/Bielik-4.5B-v3.0-Instruct-GGUF</code> - jeżeli pobrałeś go przy pomocy LM Studio już znajduje się na Twoim dysku) i porozmawiać z nim za pomocą interfejsu. Miłej zabawy!</p> <figure> <a class=glightbox href=../../../../../img/prompt_engineering/for_everyone/Clippy_pl.png data-type=image data-width=auto data-height=auto data-desc-position=bottom><img alt="Image title" src=../../../../../img/prompt_engineering/for_everyone/Clippy_pl.png style=height:65%;width:65%></a> <figcaption>Clippy w akcji</figcaption> </figure> </article> </div> <script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script> </div> <button type=button class="md-top md-icon" data-md-component=top hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg> Powrót do góry </button> </main> <footer class=md-footer> <nav class="md-footer__inner md-grid" aria-label=Stopka> <a href=../ class="md-footer__link md-footer__link--prev" aria-label="Poprzednia strona: Prompt Engineering dla każdego"> <div class="md-footer__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg> </div> <div class=md-footer__title> <span class=md-footer__direction> Poprzednia strona </span> <div class=md-ellipsis> Prompt Engineering dla każdego </div> </div> </a> <a href=../../../../Docs/LLM/Inference_and_Serving/ class="md-footer__link md-footer__link--next" aria-label="Następna strona: Inference and Serving"> <div class=md-footer__title> <span class=md-footer__direction> Następna strona </span> <div class=md-ellipsis> Inference and Serving </div> </div> <div class="md-footer__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11z"/></svg> </div> </a> </nav> <div class="md-footer-meta md-typeset"> <div class="md-footer-meta__inner md-grid"> <div class=md-copyright> <div class=md-copyright__highlight> Copyright &copy; 2025 Karol Jezierski </div> Made with <a href=https://squidfunk.github.io/mkdocs-material/ target=_blank rel=noopener> Material for MkDocs </a> </div> <div class=md-social> <a href=https://linkedin.com/in/karol-jezierski target=_blank rel=noopener title=linkedin.com class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20.447 20.452h-3.554v-5.569c0-1.328-.027-3.037-1.852-3.037-1.853 0-2.136 1.445-2.136 2.939v5.667H9.351V9h3.414v1.561h.046c.477-.9 1.637-1.85 3.37-1.85 3.601 0 4.267 2.37 4.267 5.455v6.286zM5.337 7.433a2.06 2.06 0 0 1-2.063-2.065 2.064 2.064 0 1 1 2.063 2.065m1.782 13.019H3.555V9h3.564zM22.225 0H1.771C.792 0 0 .774 0 1.729v20.542C0 23.227.792 24 1.771 24h20.451C23.2 24 24 23.227 24 22.271V1.729C24 .774 23.2 0 22.222 0z"/></svg> </a> </div> </div> </div> </footer> </div> <div class=md-dialog data-md-component=dialog> <div class="md-dialog__inner md-typeset"></div> </div> <script id=__config type=application/json>{"base": "../../../../..", "features": ["navigation.footer", "navigation.tabs", "navigation.indexes", "content.code.copy", "content.code.select", "content.code.annotate", "search.highlight", "search.suggest", "navigation.top", "navigation.tracking", "toc.follow", "content.tooltips", "content.action.edit", "content.action.view"], "search": "../../../../../assets/javascripts/workers/search.6ce7567c.min.js", "translations": {"clipboard.copied": "Skopiowano do schowka", "clipboard.copy": "Kopiuj do schowka", "search.result.more.one": "1 wi\u0119cej na tej stronie", "search.result.more.other": "# wi\u0119cej na tej stronie", "search.result.none": "Brak wynik\u00f3w wyszukiwania", "search.result.one": "Wyniki wyszukiwania: 1", "search.result.other": "Wyniki wyszukiwania: #", "search.result.placeholder": "Zacznij pisa\u0107, aby szuka\u0107", "search.result.term.missing": "Brak", "select.version": "Wybierz wersj\u0119"}}</script> <script src=../../../../../assets/javascripts/bundle.83f73b43.min.js></script> <script id=init-glightbox>const lightbox = GLightbox({"touchNavigation": true, "loop": false, "zoomable": true, "draggable": true, "openEffect": "zoom", "closeEffect": "zoom", "slideEffect": "slide"});
document$.subscribe(() => { lightbox.reload() });
</script></body> </html>